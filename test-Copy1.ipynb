{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lime\n",
      "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
      "\u001b[K     |████████████████████████████████| 275 kB 21.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.4.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.19.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.5.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.61.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (0.24.2)\n",
      "Collecting scikit-image>=0.12\n",
      "  Downloading scikit_image-0.18.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (29.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 29.2 MB 39.8 MB/s eta 0:00:01    |█████████▋                      | 8.8 MB 39.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (8.2.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.5.1)\n",
      "Collecting imageio>=2.3.0\n",
      "  Downloading imageio-2.13.1-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 19.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.3.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->lime) (1.15.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
      "Collecting pillow!=7.1.0,!=7.1.1,>=4.3.0\n",
      "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 46.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (6.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.1 MB 63.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (2.1.0)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 75.0 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: lime\n",
      "  Building wheel for lime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=520f1bca337e804fd1fe4d9b8e1e0173ce29312e6fee7f489ca25e4a2368f060\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/cb/e5/ac701e12d365a08917bf4c6171c0961bc880a8181359c66aa7\n",
      "Successfully built lime\n",
      "Installing collected packages: pillow, tifffile, PyWavelets, imageio, scikit-image, lime\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 8.2.0\n",
      "    Uninstalling Pillow-8.2.0:\n",
      "      Successfully uninstalled Pillow-8.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.2.2 requires tqdm==4.19.9, but you have tqdm 4.61.1 which is incompatible.\u001b[0m\n",
      "Successfully installed PyWavelets-1.2.0 imageio-2.13.1 lime-0.2.0.1 pillow-8.4.0 scikit-image-0.18.3 tifffile-2021.11.2\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 423 ms (started: 2021-11-29 17:41:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from catenets.models import TNet, SNet,DRNet\n",
    "#from importlib import reload  \n",
    "from catenets.models.representation_nets import SNet1, SNet2\n",
    "\n",
    "from catenets.experiments.simulation_utils import simulate_treatment_setup\n",
    "%load_ext autotime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11285 9028\n",
      "time: 112 ms (started: 2021-11-29 16:19:34 +00:00)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../antiasthma-v2/\"\n",
    "(Y_tr, T_tr, X_tr, W_tr)=pickle.load(open(data_path+'YTXW_train.pkl','rb'))\n",
    "(Y_va, T_va, X_va, W_va)=pickle.load(open(data_path+'YTXW_val.pkl','rb'))\n",
    "(Y_te, T_te, X_te, W_te)=pickle.load(open(data_path+'YTXW_test.pkl','rb'))\n",
    "#print(Y_tr.shape,Y_va.shape,Y_te.shape)\n",
    "\n",
    "tot_t = Y_tr.shape[0]\n",
    "totexs = Y_tr.shape[0]+Y_va.shape[0]+Y_te.shape[0]\n",
    "tot_tv = Y_tr.shape[0]+Y_va.shape[0]\n",
    "print(totexs,tot_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patid</th>\n",
       "      <th>phecode3</th>\n",
       "      <th>count</th>\n",
       "      <th>log_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2.397895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590421</th>\n",
       "      <td>11282</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590422</th>\n",
       "      <td>11282</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590423</th>\n",
       "      <td>11282</td>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590424</th>\n",
       "      <td>11282</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590425</th>\n",
       "      <td>11282</td>\n",
       "      <td>238</td>\n",
       "      <td>11</td>\n",
       "      <td>2.484907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353062 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        patid  phecode3  count  log_count\n",
       "52          1         7     10   2.397895\n",
       "53          1         8      1   0.693147\n",
       "54          1        10      1   0.693147\n",
       "55          1        11      3   1.386294\n",
       "56          1        14      2   1.098612\n",
       "...       ...       ...    ...        ...\n",
       "590421  11282       220      2   1.098612\n",
       "590422  11282       225      2   1.098612\n",
       "590423  11282       234      2   1.098612\n",
       "590424  11282       235      1   0.693147\n",
       "590425  11282       238     11   2.484907\n",
       "\n",
       "[353062 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20 ms (started: 2021-11-29 16:19:35 +00:00)\n"
     ]
    }
   ],
   "source": [
    "W_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 43.7 s (started: 2021-11-29 16:19:35 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_frames = [Y_tr, Y_va, Y_te]\n",
    "X_frames = [X_tr, X_va, X_te]\n",
    "T_frames = [T_tr, T_va, T_te]\n",
    "W_frames = [W_tr, W_va, W_te]\n",
    "\n",
    "\n",
    "Y = pd.concat(Y_frames)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X = pd.concat(X_frames)\n",
    "T = pd.concat(T_frames)\n",
    "W = pd.concat(W_frames)\n",
    "\n",
    "patids = W.patid.unique()\n",
    "\n",
    "T = T[\"antiasthma\"]\n",
    "T.shape,Y.shape,X.shape,W.shape\n",
    "n_pats = len(W.patid.unique())\n",
    "n_phecodes = len(W.phecode3.unique())\n",
    "W_mat = np.zeros((n_pats,n_phecodes))\n",
    "\n",
    "for row in W.iterrows():\n",
    "    pid = np.where(patids==int(row[1][\"patid\"]))\n",
    "    pcd = int(row[1][\"phecode3\"])\n",
    "    W_mat[pid,pcd] = row[1][\"log_count\"]\n",
    "    \n",
    "    \n",
    "le_dx=pickle.load(open(data_path+'le_dx.pkl','rb'))\n",
    "a = np.array(T)\n",
    "Treatment = np.zeros((len(a),6))\n",
    "ctr = 0\n",
    "for item in a:\n",
    "    Treatment[ctr][item] = 1\n",
    "    ctr = ctr+1\n",
    "Xs = np.concatenate((W_mat,X),axis=1)\n",
    "#X = Xs/np.max(Xs,axis=0)\n",
    "\n",
    "P = np.zeros(totexs)\n",
    "\n",
    "for i in range(totexs):\n",
    "    P[i] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate CATE using TNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ermse = 0.0\n",
    "cate_pred_all = []\n",
    "ctr = 0\n",
    "for k in range(5,6):\n",
    "    print(\"For treatment: \",k)\n",
    "    t = TNet(val_split_prop=0.25,n_iter=1500,batch_size=500)\n",
    "    w = np.array(Treatment[0:tot_tv,k],dtype=int)\n",
    "    y = np.array(Y[0:tot_tv],dtype=int)\n",
    "    X_train = Xs[0:tot_tv]\n",
    "    #print(X_train)\n",
    "    X_test = Xs[tot_tv :totexs]\n",
    "    #cate = cate[0:tot_tv]\n",
    "    p = P[0:tot_tv]\n",
    "    t.fit(X_train, y, w) # w is t here \n",
    "    cate_pred_train = t.predict(X_test) # without potential outcomes\n",
    "    t_test = TNet()\n",
    "    t_test.fit(X_test, Y[tot_tv :totexs], np.array(Treatment[tot_tv :totexs,k],dtype=int)) # w is t here \n",
    "    cate_pred_test = t_test.predict(X_test) \n",
    "    cate_pred_all.append(cate_pred_train)\n",
    "    ermse = ermse+(np.square(cate_pred_train - cate_pred_test).mean())\n",
    "    ctr = ctr+1\n",
    "    \n",
    "\n",
    "\n",
    "ermse = ermse/ctr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated root mean squared error for the TNet is:  0.08795806765556335\n",
      "time: 1.31 ms (started: 2021-08-12 19:14:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(\"The estimated root mean squared error for the TNet is: \",ermse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 452 ms (started: 2021-08-12 19:14:50 +00:00)\n"
     ]
    }
   ],
   "source": [
    "for k in range(5,6):\n",
    "    plt.clf()\n",
    "    n, bins, patches = plt.hist(np.array(cate_pred_all[0]),bins=100) #0 to k-1 for range 1 to 6\n",
    "    plt.axvline(linewidth=1, color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate CATE using SNet1 = CFRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " For treatment:  5\n",
      "Epoch: 0, current validation loss 0.18955309689044952\n",
      "Now fitting on test data for ERMSE\n",
      "Epoch: 0, current validation loss 0.18453781306743622\n",
      "time: 26.4 s (started: 2021-09-10 17:59:24 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# estimate CATE using SNet1 =CFRNet\n",
    "\n",
    "ermse = 0.0\n",
    "cate_pred_all = []\n",
    "ctr = 0\n",
    "for k in range(5,6):\n",
    "    print(\"\\n For treatment: \",k)\n",
    "    \n",
    "    t = SNet1(val_split_prop=0.25,n_iter=1500,batch_size=100)\n",
    "    w = np.array(Treatment[0:tot_tv,k],dtype=int)\n",
    "    y = np.array(Y[0:tot_tv],dtype=int)\n",
    "    X_train = Xs[0:tot_tv]\n",
    "    #print(X_train)\n",
    "    X_test = Xs[tot_tv :totexs]\n",
    "    #cate = cate[0:tot_tv]\n",
    "    p = P[0:tot_tv]\n",
    "    t.fit(X_train, y, w) # w is t here \n",
    "    cate_pred_train = t.predict(X_test) # without potential outcomes\n",
    "    t_test = SNet1(val_split_prop=0.1,n_iter=1500,batch_size=100)\n",
    "    print(\"Now fitting on test data for ERMSE\")\n",
    "    t_test.fit(X_test, Y[tot_tv :totexs], np.array(Treatment[tot_tv :totexs,k],dtype=int)) # w is t here \n",
    "    cate_pred_test = t_test.predict(X_test) \n",
    "    cate_pred_all.append(cate_pred_train)\n",
    "    ermse = ermse+(np.square(cate_pred_train - cate_pred_test).mean())\n",
    "    ctr = ctr+1\n",
    "    \n",
    "\n",
    "    \n",
    "ermse = ermse/ctr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated root mean squared error for the CFRNet is:  0.05476769432425499\n",
      "time: 1.31 ms (started: 2021-09-10 17:59:51 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(\"The estimated root mean squared error for the CFRNet is: \",ermse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 350 ms (started: 2021-09-10 18:00:20 +00:00)\n"
     ]
    }
   ],
   "source": [
    "for k in range(5,6):\n",
    "    plt.clf()\n",
    "    n, bins, patches = plt.hist(np.array(cate_pred_train),bins=100) #0 to k-1 for range 1 to 6\n",
    "    plt.axvline(linewidth=1, color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f295c657a90>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAASo0lEQVR4nO3df5BddXnH8fcjbBrGoJFkCRlCWEYYFJxkCWuqY6uUKEOrw48pAyqlsaQTHLGKFEuKf9RWhEAHgRmYDhmxTWuooWkZGGmtNMIwZSqQlJQCwUIYkKX5gQGtVIIEnv6xJ2nY3M2e3b2/vrvv18zOvefcc/c+Z5P97Pc+93vOicxEklSet3W6AEnS+BjgklQoA1ySCmWAS1KhDHBJKtTB7Xyx2bNnZ19fXztfUqpn40Y4+eROVyE1tHHjxp9kZu/w9W0N8L6+PjZs2NDOl5TqiQD/b6pLRcRzjdbbQpGkQhngklQoA1ySCtXWHngjr7/+OoODg+zatavTpXSl6dOnM2/ePHp6ejpdiqQu0/EAHxwc5NBDD6Wvr4+I6HQ5XSUz2blzJ4ODgxxzzDGdLkdSl+l4C2XXrl3MmjXL8G4gIpg1a5bvTiQ1VCvAI2JmRKyLiCcjYnNEfDAiDouIeyLiqer2XeMtwvAemT8bSSOpOwK/EfheZr4HWAhsBlYA6zPzOGB9tSxJapNRe+AR8U7gw8BnADLzl8AvI+JM4JRqs9XAfcDlEy2ob8XdE/0Wb/Hsyo+Pus22bdu45JJLePjhh5k5cyZz5szhhhtuYOHChRx//PF7t3vooYe47bbb+PKXv8yRRx7Jrl27uOiii/jSl74EwFe/+lWuvfZann32WQ4//HAAZsyYwSuvvHLA17/qqqu44oorJrCXkqaiOiPwY4AXgb+MiEci4psR8XZgTmZurbbZBsxp9OSIWB4RGyJiw4svvticqpsoMzn77LM55ZRT2LJlCxs3buTqq69m+/btvPvd72bTpk17v6ZNmwbAeeedx6ZNm3jggQf4+te/zvPPP7/3+82ePZvrrrtuTDVcddVVTd2nqaxvxd17v6TJrk6AHwwsAv4iM08C/pdh7ZIcuqxPw0v7ZOaqzBzIzIHe3v0O5e+4e++9l56eHj772c/uXbdw4UKOOuqoUZ87a9Ysjj32WLZu3bp33YUXXsjatWt56aWX9tv+29/+NosXL6a/v5+LLrqIN954gxUrVvDqq6/S39/P+eef35ydkjQl1AnwQWAwMx+sltcxFOjbI2IuQHW7ozUlttZjjz3GySOcxGjLli309/fT39/PxRdfvN/jP/7xj9m1axcLFizYu27GjBlceOGF3HjjjW/ZdvPmzaxdu5YHHniATZs2cdBBB7FmzRpWrlzJIYccwqZNm1izZk1zd07SpDZqDzwzt0XE8xFxfGb+CFgCPFF9LQVWVrd3trTSDtjTQhlu7dq13H///Tz55JPcdNNNTJ8+/S2Pf+ELX6C/v5/LLrts77r169ezceNG3v/+9wPw6quv7u2TS9J41D2Q5w+ANRExDXgG+D2GRu+3R8Qy4Dng3NaU2Fonnngi69atG9NzzjvvPG666SY2bNjAaaedxhlnnMERRxyx9/GZM2fy6U9/mptvvnnvusxk6dKlXH311U2rXdLUVmsaYWZuqvrYCzLzrMx8OTN3ZuaSzDwuMz+amfs3fQtw6qmn8tprr7Fq1aq96x599NG3fDA5koGBAS644IL92iUAl156Kbfccgu7d+8GYMmSJaxbt44dO4Y6TS+99BLPPTd0hsienh5ef/31ZuyOpCmk44fSD1dn2l8zRQR33HEHl1xyCddccw3Tp0+nr6+PG264odbzL7/8chYtWrTfNMDZs2dz9tlnc/311wNwwgkncOWVV3Laaafx5ptv0tPTw80338zRRx/N8uXLWbBgAYsWLbIPLqm2GJpA0h4DAwM5/IIOmzdv5r3vfW/baijRVP4Z7TsdsM4f97Fuv1cEtPF3QRqLiNiYmQPD13f8XCiSpPExwCWpUF0R4O1s45TGn42kkXQ8wKdPn87OnTsNqgb2nA98+DxzSYIumIUyb948BgcH6cbzpHSDPVfkkaThOh7gPT09Xm1Gksah4wEuwQSm/0lTWMd74JKk8THAJalQtlBUPC/eoKnKEbgkFcoAl6RC2UKRmmSkVo6zatQqjsAlqVAGuCQVygCXpEIZ4JJUKANckgplgEtSoZxGqCmpUyfPOtBRo0431Fg5ApekQhngklQoA1ySClWrBx4RzwI/B94AdmfmQEQcBqwF+oBngXMz8+XWlClJGm4sI/DfyMz+zByollcA6zPzOGB9tSxJapOJtFDOBFZX91cDZ024GklSbXUDPIHvR8TGiFherZuTmVur+9uAOY2eGBHLI2JDRGzwyvOS1Dx154H/Wma+EBGHA/dExJP7PpiZGRHZ6ImZuQpYBTAwMNBwG0nS2NUagWfmC9XtDuAOYDGwPSLmAlS3O1pVpCRpf6MGeES8PSIO3XMfOA14DLgLWFptthS4s1VFSpL2V6eFMge4IyL2bH9bZn4vIh4Gbo+IZcBzwLmtK1NTSbsvUty34m6e3XNb43D2dh+G36nD/tX9Rg3wzHwGWNhg/U5gSSuKkiSNziMxJalQBrgkFcoAl6RCGeCSVCgDXJIK5RV5pAlo95THOpx2OHU4ApekQhngklQoWyhSi3Vjm0WTgyNwSSqUAS5JhTLAJalQBrgkFcoAl6RCGeCSVCinEapI45maNxmm83mUpfblCFySCmWAS1KhbKGorWwBjGwytHjUXo7AJalQBrgkFcoAl6RC2QNXMTrZI+72/nS316fWcAQuSYUywCWpUAa4JBWqdoBHxEER8UhEfLdaPiYiHoyIpyNibURMa12ZkqThxjIC/yKweZ/la4DrM/NY4GVgWTMLkyQdWK0Aj4h5wMeBb1bLAZwKrKs2WQ2c1YL6JEkjqDuN8Abgj4BDq+VZwE8zc3e1PAgc2eiJEbEcWA4wf/78cReqsnjIvNR6o47AI+ITwI7M3DieF8jMVZk5kJkDvb294/kWkqQG6ozAPwScERG/BUwH3gHcCMyMiIOrUfg84IXWlSlJGm7UEXhm/nFmzsvMPuCTwA8y83zgXuCcarOlwJ0tq1KStJ+JzAO/HLg0Ip5mqCd+a3NKkiTVMaZzoWTmfcB91f1ngMXNL0mSVIdHYkpSoTwboTqm28+gZ33qdo7AJalQBrgkFcoWiiat8bQYbEuoJI7AJalQBrgkFcoAl6RCGeCSVCgDXJIKZYBLUqGcRqimcQqe1F6OwCWpUAa4JBXKFoo0iXlt0snNEbgkFcoAl6RCGeCSVCh74Bo3pw1KneUIXJIKZYBLUqFsoWhMbJtI3cMRuCQVygCXpEIZ4JJUqFEDPCKmR8RDEfEfEfF4RPxptf6YiHgwIp6OiLURMa315UqS9qgzAn8NODUzFwL9wOkR8QHgGuD6zDwWeBlY1rIqJUn7GTXAc8gr1WJP9ZXAqcC6av1q4KxWFChJaqzWNMKIOAjYCBwL3AxsAX6amburTQaBI0d47nJgOcD8+fMnWq8K5NRDqTVqfYiZmW9kZj8wD1gMvKfuC2TmqswcyMyB3t7e8VUpSdrPmGahZOZPgXuBDwIzI2LPCH4e8EJzS5MkHUidWSi9ETGzun8I8DFgM0NBfk612VLgzhbVKElqoE4PfC6wuuqDvw24PTO/GxFPAN+JiCuBR4BbW1in2swruUjdb9QAz8xHgZMarH+GoX64JKkDPBJTkgplgEtSoQxwSSqUAS5JhTLAJalQXpFHe3nIu1QWR+CSVCgDXJIKZQtFmiI8unbycQQuSYUywCWpUAa4JBXKAJekQhngklQoA1ySCuU0QmmKc3phuRyBS1KhDHBJKpQtlCmuzgmsPMmV1J0cgUtSoQxwSSqUAS5JhbIHLk1Bfq4xOTgCl6RCGeCSVCgDXJIKNWqAR8RREXFvRDwREY9HxBer9YdFxD0R8VR1+67WlytJ2qPOCHw38IeZeQLwAeDiiDgBWAGsz8zjgPXVsiSpTUYN8Mzcmpn/Xt3/ObAZOBI4E1hdbbYaOKtFNUqSGhjTNMKI6ANOAh4E5mTm1uqhbcCcEZ6zHFgOMH/+/HEXKqlzhk879KyF3aH2h5gRMQP4e+CSzPyffR/LzASy0fMyc1VmDmTmQG9v74SKlST9v1oBHhE9DIX3msz8h2r19oiYWz0+F9jRmhIlSY2M2kKJiABuBTZn5jf2eeguYCmwsrq9syUVquk8Ck8jqXtxh7FeBMKLRrRGnR74h4ALgP+MiE3VuisYCu7bI2IZ8BxwbksqlCQ1NGqAZ+a/AjHCw0uaW44kqS6PxJSkQhngklQoA1ySCmWAS1KhvKDDJObULWlycwQuSYUywCWpUAa4JBXKHvgkYK9bmpocgUtSoQxwSSqULZQuN5GzvkntZjuvvRyBS1KhDHBJKpQtFEkN1W3HTaRtZ8tlYhyBS1KhDHBJKpQBLkmFsgcuqa1G6pnbDx87R+CSVCgDXJIKZQulQ8bzdnEibzE9QlOafByBS1KhDHBJKpQBLkmFGrUHHhHfAj4B7MjM91XrDgPWAn3As8C5mfly68qcHOr0oe1VS2/l9MKR1RmB/xVw+rB1K4D1mXkcsL5aliS10agBnpn3Ay8NW30msLq6vxo4q7llSZJGM94e+JzM3Frd3wbMGWnDiFgeERsiYsOLL744zpeTJA034Q8xMzOBPMDjqzJzIDMHent7J/pykqTKeAN8e0TMBahudzSvJElSHeMN8LuApdX9pcCdzSlHklRXnWmEfwucAsyOiEHgT4CVwO0RsQx4Dji3lUVOdk4dlMbO6YU1AjwzPzXCQ0uaXIskaQw8ElOSCuXZCCW1hK3B1nMELkmFMsAlqVAGuCQVygCXpEIZ4JJUKANckgrlNMIWcPqUNDHd+DvUjUd+OgKXpEIZ4JJUKANckgo15Xrgw3trE+lldbJP1409QqnVRvp/36rf627pdY/EEbgkFcoAl6RCTbkWyoGM9Pas299GSRpZnZZIqS1JR+CSVCgDXJIKNSVaKM18e1TqWy1JbzWR3+VumaniCFySCmWAS1KhDHBJKlQxPfA6U/y6pS8lqbPqHrE53u8z1ue2Ko8cgUtSoQxwSSpUMS2Usar71sdpgZImopMZMqEReEScHhE/ioinI2JFs4qSJI1u3AEeEQcBNwO/CZwAfCoiTmhWYZKkA5vICHwx8HRmPpOZvwS+A5zZnLIkSaOJzBzfEyPOAU7PzN+vli8AfjUzPz9su+XA8mrxeOBH4y+3I2YDP+l0EW3mPk8N7nM5js7M3uErW/4hZmauAla1+nVaJSI2ZOZAp+toJ/d5anCfyzeRFsoLwFH7LM+r1kmS2mAiAf4wcFxEHBMR04BPAnc1pyxJ0mjG3ULJzN0R8Xngn4GDgG9l5uNNq6x7FNv+mQD3eWpwnws37g8xJUmd5aH0klQoA1ySCmWANxARh0XEPRHxVHX7rgNs+46IGIyIm9pZYzPV2d+I6I+If4uIxyPi0Yg4rxO1TtRop3+IiF+JiLXV4w9GRF8HymyqGvt8aUQ8Uf27ro+IoztRZzPVPc1HRPx2RGREFDm10ABvbAWwPjOPA9ZXyyP5GnB/W6pqnTr7+wvgdzPzROB04IaImNm+Eieu5ukflgEvZ+axwPXANe2tsrlq7vMjwEBmLgDWAde2t8rmqnuaj4g4FPgi8GB7K2weA7yxM4HV1f3VwFmNNoqIk4E5wPfbU1bLjLq/mflfmflUdf+/gR3AfkeGdbk6p3/Y92exDlgSEdHGGptt1H3OzHsz8xfV4g8ZOqajZHVP8/E1hv5A72pncc1kgDc2JzO3Vve3MRTSbxERbwOuAy5rZ2EtMur+7isiFgPTgC2tLqzJjgSe32d5sFrXcJvM3A38DJjVlupao84+72sZ8E8traj1Rt3niFgEHJWZRZ9PetKeD3w0EfEvwBENHvrKvguZmRHRaK7l54B/zMzBEgZoTdjfPd9nLvA3wNLMfLO5VaqTIuJ3gAHgI52upZWqwdc3gM90uJQJm7IBnpkfHemxiNgeEXMzc2sVWDsabPZB4Ncj4nPADGBaRLySmV15XvQm7C8R8Q7gbuArmfnDFpXaSnVO/7Bnm8GIOBh4J7CzPeW1RK1TXkTERxn6Y/6RzHytTbW1ymj7fCjwPuC+avB1BHBXRJyRmRvaVmUT2EJp7C5gaXV/KXDn8A0y8/zMnJ+ZfQy1Uf66W8O7hlH3tzpdwh0M7ee6NtbWTHVO/7Dvz+Ic4AdZ9tFuo+5zRJwE3AKckZkN/3gX5oD7nJk/y8zZmdlX/f7+kKF9Lyq8wQAfyUrgYxHxFPDRapmIGIiIb3a0staos7/nAh8GPhMRm6qv/o5UO05VT3vP6R82A7dn5uMR8WcRcUa12a3ArIh4GriUA89A6no19/nPGXoX+XfVv2vR5zSquc+TgofSS1KhHIFLUqEMcEkqlAEuSYUywCWpUAa4JBXKAJekQhngklSo/wMh8JX75Kw0/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 394 ms (started: 2021-08-13 21:10:43 +00:00)\n"
     ]
    }
   ],
   "source": [
    "bins = np.linspace(-0.5, 0.5, 100)\n",
    "data1 = [cate_pred_test.flatten()]\n",
    "plt.hist(data1, bins, label = ['CFRNet'])\n",
    "plt.axvline(linewidth=1, color='r')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimate CATE using SNet = S Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " For treatment:  5\n",
      "Epoch: 0, current validation loss 473.84136962890625\n",
      "Epoch: 50, current validation loss 62.80744171142578\n",
      "Epoch: 100, current validation loss 11.953031539916992\n",
      "Epoch: 150, current validation loss 3.2879958152770996\n",
      "Epoch: 200, current validation loss 1.4003797769546509\n",
      "Epoch: 250, current validation loss 0.9190294742584229\n",
      "Epoch: 300, current validation loss 0.7818131446838379\n",
      "Epoch: 350, current validation loss 0.7391136288642883\n",
      "Epoch: 400, current validation loss 0.7237522602081299\n",
      "Now fitting on test data for ERMSE\n",
      "Epoch: 0, current validation loss 488.7472839355469\n",
      "Epoch: 50, current validation loss 264.3348693847656\n",
      "Epoch: 100, current validation loss 146.90472412109375\n",
      "Epoch: 150, current validation loss 84.13914489746094\n",
      "Epoch: 200, current validation loss 49.5791015625\n",
      "Epoch: 250, current validation loss 30.084522247314453\n",
      "Epoch: 300, current validation loss 18.793746948242188\n",
      "Epoch: 350, current validation loss 12.084972381591797\n",
      "Epoch: 400, current validation loss 7.998276233673096\n",
      "Epoch: 450, current validation loss 5.436212062835693\n",
      "Epoch: 500, current validation loss 3.805044174194336\n",
      "Epoch: 550, current validation loss 2.7469594478607178\n",
      "Epoch: 600, current validation loss 2.0763163566589355\n",
      "Epoch: 650, current validation loss 1.6290630102157593\n",
      "Epoch: 700, current validation loss 1.3432598114013672\n",
      "Epoch: 750, current validation loss 1.0921895503997803\n",
      "Epoch: 800, current validation loss 0.9485070109367371\n",
      "Epoch: 850, current validation loss 0.8658216595649719\n",
      "Epoch: 900, current validation loss 0.7749883532524109\n",
      "Epoch: 950, current validation loss 0.7288506031036377\n",
      "Epoch: 1000, current validation loss 0.6927261352539062\n",
      "time: 4min 36s (started: 2021-08-12 20:41:07 +00:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ermse = 0.0\n",
    "cate_pred_all = []\n",
    "ctr = 0 \n",
    "for k in range(5,6):\n",
    "    print(\"\\n For treatment: \",k)\n",
    "    \n",
    "    t = SNet(val_split_prop=0.25,n_iter=1500,batch_size=500)\n",
    "    w = np.array(Treatment[0:tot_tv,k],dtype=int)\n",
    "    y = np.array(Y[0:tot_tv],dtype=int)\n",
    "    X_train = X[0:tot_tv]\n",
    "    #print(X_train)\n",
    "    X_test = X[tot_tv :totexs]\n",
    "    #cate = cate[0:tot_tv]\n",
    "    p = P[0:tot_tv]\n",
    "    t.fit(X_train, y, w) # w is t here \n",
    "    cate_pred_train = t.predict(X_test) # without potential outcomes\n",
    "    t_test = SNet(val_split_prop=0.1,n_iter=1500,batch_size=500)\n",
    "    print(\"Now fitting on test data for ERMSE\")\n",
    "    t_test.fit(X_test, Y[tot_tv :totexs], np.array(Treatment[tot_tv :totexs,k],dtype=int)) # w is t here \n",
    "    cate_pred_test = t_test.predict(X_test) \n",
    "    cate_pred_all.append(cate_pred_train)\n",
    "    ermse = ermse+(np.square(cate_pred_train - cate_pred_test).mean())\n",
    "    ctr = ctr+1\n",
    "    \n",
    "\n",
    "    \n",
    "ermse = ermse/ctr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated root mean squared error for the SNet is:  0.03364619240164757\n",
      "time: 985 µs (started: 2021-08-12 20:45:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(\"The estimated root mean squared error for the SNet is: \",ermse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 334 ms (started: 2021-08-12 20:45:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "for k in range(5,6):\n",
    "    plt.clf()\n",
    "    n, bins, patches = plt.hist(np.array(cate_pred_all[0]),bins=100) #0 to k-1 for range 1 to 6\n",
    "    plt.axvline(linewidth=1, color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimate CATE using SNet2 = DragonNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " For treatment:  5\n",
      "Epoch: 0, current validation loss 0.8309612274169922\n",
      "Now fitting on test data for ERMSE\n",
      "Epoch: 0, current validation loss 0.8949765563011169\n",
      "Epoch: 50, current validation loss 0.611284613609314\n",
      "Epoch: 100, current validation loss 0.5898926258087158\n",
      "time: 38.2 s (started: 2021-11-29 16:20:18 +00:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ermse = 0.0\n",
    "cate_pred_all = []\n",
    "ctr = 0\n",
    "for k in range(5,6):\n",
    "    print(\"\\n For treatment: \",k)\n",
    "    \n",
    "    t = SNet2(val_split_prop=0.25,n_iter=1500,batch_size=500)\n",
    "    w = np.array(Treatment[0:tot_tv,k],dtype=int)\n",
    "    y = np.array(Y[0:tot_tv],dtype=int)\n",
    "    X_train = Xs[0:tot_tv]\n",
    "    #print(X_train)\n",
    "    X_test = Xs[tot_tv :totexs]\n",
    "    #cate = cate[0:tot_tv]\n",
    "    p = P[0:tot_tv]\n",
    "    t.fit(X_train, y, w) # w is t here \n",
    "    cate_pred_train = t.predict(X_test) # without potential outcomes\n",
    "    t_test = SNet2(val_split_prop=0.1,n_iter=1500,batch_size=500)\n",
    "    print(\"Now fitting on test data for ERMSE\")\n",
    "    t_test.fit(X_test, Y[tot_tv :totexs], np.array(Treatment[tot_tv :totexs,k],dtype=int)) # w is t here \n",
    "    cate_pred_test = t_test.predict(X_test) \n",
    "    cate_pred_all.append(cate_pred_train)\n",
    "    ermse = ermse+(np.square(cate_pred_train - cate_pred_test).mean())\n",
    "    ctr = ctr+1\n",
    "    \n",
    "\n",
    "    \n",
    "ermse = ermse/ctr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated root mean squared error for the DragonNet is:  0.04019579291343689\n",
      "time: 1.46 ms (started: 2021-11-29 16:20:57 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(\"The estimated root mean squared error for the DragonNet is: \",ermse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 374 ms (started: 2021-11-29 16:20:57 +00:00)\n"
     ]
    }
   ],
   "source": [
    "for k in range(5,6):\n",
    "    plt.clf()\n",
    "    n, bins, patches = plt.hist(np.array(cate_pred_test),bins=100) #0 to k-1 for range 1 to 6\n",
    "    plt.axvline(linewidth=1, color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DR Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " For treatment:  5\n",
      "Training first stage with all data (no data splitting)\n",
      "Training PO_0 Net\n",
      "Epoch: 0, current validation loss: 0.1632564812898636\n",
      "Training PO_1 Net\n",
      "Epoch: 0, current validation loss: 0.47067999839782715\n",
      "Training propensity net\n",
      "Epoch: 0, current validation loss: 0.5933991074562073\n",
      "Training second stage.\n",
      "Epoch: 0, current validation loss: 1.0979541540145874\n",
      "Now fitting on test data for ERMSE\n",
      "Epoch: 0, current validation loss 0.18453781306743622\n",
      "time: 57.1 s (started: 2021-08-27 19:00:53 +00:00)\n"
     ]
    }
   ],
   "source": [
    "ermse = 0.0\n",
    "cate_pred_all = []\n",
    "ctr = 0\n",
    "for k in range(5,6):\n",
    "    print(\"\\n For treatment: \",k)\n",
    "    \n",
    "    t = DRNet(val_split_prop=0.25,n_iter=1500,batch_size=100)\n",
    "    w = np.array(Treatment[0:tot_tv,k],dtype=int)\n",
    "    y = np.array(Y[0:tot_tv],dtype=int)\n",
    "    X_train = Xs[0:tot_tv]\n",
    "    #print(X_train)\n",
    "    X_test = Xs[tot_tv :totexs]\n",
    "    #cate = cate[0:tot_tv]\n",
    "    p = P[0:tot_tv]\n",
    "    t.fit(X_train, y, w) # w is t here \n",
    "    cate_pred_train = t.predict(X_test) # without potential outcomes\n",
    "    t_test = SNet1(val_split_prop=0.1,n_iter=1500,batch_size=100)\n",
    "    print(\"Now fitting on test data for ERMSE\")\n",
    "    t_test.fit(X_test, Y[tot_tv :totexs], np.array(Treatment[tot_tv :totexs,k],dtype=int)) # w is t here \n",
    "    cate_pred_test = t_test.predict(X_test) \n",
    "    cate_pred_all.append(cate_pred_train)\n",
    "    ermse = ermse+(np.square(cate_pred_train - cate_pred_test).mean())\n",
    "    ctr = ctr+1\n",
    "    \n",
    "\n",
    "    \n",
    "ermse = ermse/ctr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated root mean squared error for the DRNet is:  0.04019579291343689\n",
      "time: 1.68 ms (started: 2021-11-29 16:22:26 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(\"The estimated root mean squared error for the DRNet is: \",ermse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the IF-PEHE for test set for a given model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.23.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 256 ms (started: 2021-11-29 16:22:31 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def prepare(y, tr, w, x, rx2id, target):\n",
    "    patid_temp = list(w['patid'].unique())\n",
    "    temp_le = preprocessing.LabelEncoder()\n",
    "    temp_le.fit(list(patid_temp))\n",
    "    w['row_idx'] = temp_le.transform(w['patid'])\n",
    "    \n",
    "    w_sparse = csr_matrix((w['log_count'], (w['row_idx'], w['phecode3'])))\n",
    "    w = w_sparse.toarray()\n",
    "    \n",
    "    x_temp = np.concatenate((w, x.values), axis=1)\n",
    "    \n",
    "    treatment_train = [0] * len(tr)\n",
    "    temp_index = tr.index\n",
    "    idx = 0\n",
    "\n",
    "    def get_classes(value):\n",
    "        return [k for k, v in rx2id.items() if v == value]\n",
    "\n",
    "    for i in temp_index:\n",
    "        classes = tr.loc[i, 'antiasthma']\n",
    "        if (classes != target):\n",
    "            treatment_train[idx] = 'control'\n",
    "        else:\n",
    "            treatment_train[idx] = 'treatment'\n",
    "        idx += 1\n",
    "        \n",
    "    treatment = pd.DataFrame(treatment_train)\n",
    "    treatment.index = temp_index\n",
    "    treatment.columns = ['treatment']\n",
    "    \n",
    "    y = pd.DataFrame(y)\n",
    "    feature_df = pd.DataFrame(x_temp)\n",
    "    feature_df.index = y.index\n",
    "    \n",
    "    df = pd.concat([y, treatment, tr, feature_df], axis=1)\n",
    "    df.index = np.arange(0, len(df))\n",
    "    return df\n",
    "\n",
    "le_dx=pickle.load(open(data_path+'le_dx.pkl','rb'))\n",
    "le_patid=pickle.load(open(data_path+'le_patid.pkl','rb'))\n",
    "selected_patient_feature=['age_onset','obs_win','female']+['race__'+c for c in ['A','B','H','U','W']]\n",
    "rx2id = pickle.load(open(data_path+'drug_dict.pkl', 'rb'))\n",
    "\n",
    "target = 5\n",
    "df_val0 = prepare(Y_va, T_va, W_va, X_va, rx2id, target)\n",
    "df_test0 = prepare(Y_te, T_te, W_te, X_te, rx2id, target)\n",
    "df_train0 = prepare(Y_tr, T_tr, W_tr, X_tr, rx2id, target)\n",
    "\n",
    "x_train0 = df_train0.iloc[:, 5:]\n",
    "x_test0 = df_test0.iloc[:, 5:]\n",
    "x_val0 = df_val0.iloc[:, 5:]\n",
    "\n",
    "y_val = df_val0['adrd']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6770</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6771 rows × 249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5    6         7    \\\n",
       "0     0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  2.397895   \n",
       "1     0.0  0.000000  1.098612  1.098612  0.693147  0.693147  0.0  2.639057   \n",
       "2     0.0  0.000000  0.000000  0.000000  0.000000  2.197225  0.0  0.000000   \n",
       "3     0.0  0.000000  0.000000  0.000000  0.000000  1.791759  0.0  0.000000   \n",
       "4     0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "...   ...       ...       ...       ...       ...       ...  ...       ...   \n",
       "6766  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "6767  0.0  0.000000  0.693147  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "6768  0.0  0.000000  0.693147  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "6769  0.0  0.000000  0.693147  0.000000  0.000000  1.386294  0.0  0.000000   \n",
       "6770  0.0  0.693147  0.000000  1.098612  0.000000  0.000000  0.0  1.386294   \n",
       "\n",
       "           8         9    ...  239       240  241   242  243  244  245  246  \\\n",
       "0     0.693147  0.000000  ...  0.0  0.000000  0.0  75.0  1.0  1.0  0.0  0.0   \n",
       "1     1.386294  0.000000  ...  0.0  0.000000  0.0  72.0  0.0  0.0  0.0  0.0   \n",
       "2     0.000000  0.000000  ...  0.0  0.000000  0.0  74.0  0.0  0.0  0.0  0.0   \n",
       "3     1.098612  0.693147  ...  0.0  0.000000  0.0  83.0  1.0  0.0  0.0  1.0   \n",
       "4     0.000000  0.000000  ...  0.0  0.000000  0.0  84.0  0.0  0.0  0.0  0.0   \n",
       "...        ...       ...  ...  ...       ...  ...   ...  ...  ...  ...  ...   \n",
       "6766  0.000000  0.000000  ...  0.0  0.000000  0.0  90.0  0.0  0.0  0.0  0.0   \n",
       "6767  0.000000  0.000000  ...  0.0  0.000000  0.0  83.0  1.0  0.0  0.0  0.0   \n",
       "6768  0.000000  0.000000  ...  0.0  0.000000  0.0  88.0  0.0  0.0  0.0  1.0   \n",
       "6769  0.000000  0.000000  ...  0.0  0.693147  0.0  89.0  0.0  0.0  0.0  0.0   \n",
       "6770  0.000000  0.000000  ...  0.0  0.000000  0.0  83.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "      247  248  \n",
       "0     0.0  0.0  \n",
       "1     0.0  1.0  \n",
       "2     0.0  1.0  \n",
       "3     0.0  0.0  \n",
       "4     0.0  1.0  \n",
       "...   ...  ...  \n",
       "6766  0.0  1.0  \n",
       "6767  0.0  1.0  \n",
       "6768  0.0  0.0  \n",
       "6769  0.0  1.0  \n",
       "6770  0.0  1.0  \n",
       "\n",
       "[6771 rows x 249 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.5 ms (started: 2021-11-29 16:22:31 +00:00)\n"
     ]
    }
   ],
   "source": [
    "x_train0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:40] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=336, num_parallel_tree=1,\n",
       "              random_state=1108, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11min 1s (started: 2021-11-29 16:22:32 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "xgb = XGBClassifier(max_depth=6, random_state=1105, n_estimators=100)\n",
    "xgb_plugin1 = XGBClassifier(max_depth=6, random_state=1105, n_estimators=100)\n",
    "xgb_plugin0 = XGBClassifier(max_depth=6, random_state=1108, n_estimators=100)\n",
    "\n",
    "x0 = df_train0.loc[df_train0['treatment'] == 'control', 0:248]\n",
    "y0 = df_train0.loc[df_train0['treatment'] == 'control', 'adrd']\n",
    "xgb_plugin0.fit(x0, y0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:33:37] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=336, num_parallel_tree=1,\n",
       "              random_state=1105, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6min 59s (started: 2021-11-29 16:33:33 +00:00)\n"
     ]
    }
   ],
   "source": [
    "x1 = df_train0.loc[df_train0['treatment'] == 'treatment', 0:248]\n",
    "y1 = df_train0.loc[df_train0['treatment'] == 'treatment', 'adrd']\n",
    "xgb_plugin1.fit(x1, y1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 660 ms (started: 2021-11-29 16:40:32 +00:00)\n"
     ]
    }
   ],
   "source": [
    "y_pred0 = xgb_plugin0.predict(x_test0)\n",
    "y_pred1 = xgb_plugin1.predict(x_test0)\n",
    "t_plugin = y_pred1 - y_pred0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:45] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=336, num_parallel_tree=1,\n",
       "              random_state=1105, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13min 36s (started: 2021-11-29 16:40:33 +00:00)\n"
     ]
    }
   ],
   "source": [
    "t = df_train0['treatment']\n",
    "\n",
    "treatment = [0] * len(t)\n",
    "for i in range(len(t)):\n",
    "    if t[i] == 'control':\n",
    "        treatment[i] = 0\n",
    "    else:\n",
    "        treatment[i] = 1\n",
    "\n",
    "xgb.fit(x_train0,treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.7 ms (started: 2021-11-29 16:54:09 +00:00)\n"
     ]
    }
   ],
   "source": [
    "cate = cate_pred_train.flatten()\n",
    "\n",
    "\n",
    "\n",
    "t_test = df_test0['treatment']\n",
    "#print(t_test)\n",
    "treatment_test = [0] * len(t_test)\n",
    "for i in range(len(t_test)):\n",
    "    if t_test[i] == 'control':\n",
    "        treatment_test[i] = 0\n",
    "    else:\n",
    "        treatment_test[i] = 1 \n",
    "        \n",
    "y_test = df_test0['adrd']\n",
    "\n",
    "t_val = df_val0['treatment']\n",
    "treatment_val = [0] * len(t_val)\n",
    "for i in range(len(t_val)):\n",
    "    if t_val[i] == 'control':\n",
    "        treatment_val[i] = 0\n",
    "    else:\n",
    "        treatment_val[i] = 1 \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        , -0.        , -0.        , ...,  4.55257702,\n",
       "       -0.        , -0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 361 ms (started: 2021-11-29 16:54:09 +00:00)\n"
     ]
    }
   ],
   "source": [
    "plug_in = (t_plugin-cate)**2\n",
    "ps = xgb.predict_proba(x_test0)[:, 1]\n",
    "a = (treatment_test - ps)\n",
    "ident = np.array([1]*len(ps))\n",
    "ps\n",
    "\n",
    "c = (ps*(ident-ps))\n",
    "c\n",
    "\n",
    "b = np.array([2]*len(treatment_test))*treatment_test*(treatment_test-ps) / c\n",
    "\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.15 ms (started: 2021-11-29 16:54:10 +00:00)\n"
     ]
    }
   ],
   "source": [
    "y_pred1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.573654\n",
      "time: 428 ms (started: 2021-11-29 16:54:10 +00:00)\n"
     ]
    }
   ],
   "source": [
    "l_de = (ident - b) * t_plugin**2 + b*y_val*(t_plugin - cate) + (- a*(t_plugin - cate)**2 + cate**2)\n",
    "\n",
    "\n",
    "print(np.sum(l_de) + np.sum(plug_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
